% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrartcl}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother

\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Title of Project},
  pdfauthor={Student Name},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{Leveraging Alternative Data for Mixed Martial Arts Betting Markets}
\author{Eugene Han}
\date{January 22, 2025}

\begin{document}
\maketitle


Advised by: Brian Macdonald and Robert Wooster, Statistics \& Data Science

\section{Introduction}\label{introduction}

Sports betting has experienced a dramatic rise in popularity and financial volume over the past decade, fueled by increasing legalization, the proliferation of online platforms, and widespread media coverage. In 2022 alone, the global sports betting market was valued at over \$83 billion, with projections estimating continued growth at an annual rate of 10.3\% through 2030.

Among sports gaining traction globally, mixed martial arts (MMA)---particularly through the Ultimate Fighting Championship (UFC), the sport’s leading promotion---has seen exponential growth in both viewership and fan engagement. This surge in popularity has naturally extended to betting markets, where wagers on UFC fights now constitute a significant share of betting activity.

Despite its popularity, modeling UFC fights presents unique challenges. Unlike team sports with well-established datasets and long histories of play, MMA data is both scarce and sparse. Fighter performance metrics are often incomplete or inconsistent, and external variables such as weight cuts, injuries, and stylistic mismatches contribute to the sport’s inherent volatility. These factors make accurately predicting outcomes particularly challenging and suggest the presence of inefficiencies in the betting markets. This project explores the potential to capitalize on these inefficiencies using novel approaches with respect to both data and methodology.

\section{Problem Statement}\label{problem-statement}

\subsection{Problem}\label{problem}

Most public research and existing projects related to UFC betting markets focus exclusively on data from a single source, UFC Stats, due to its ease of access and comprehensive fight statistics. While valuable, this narrow focus may overlook additional insights that could be gained from incorporating a broader range of data sources. My approach seeks to address this limitation by leveraging diverse and unconventional datasets alongside UFC Stats to uncover new signals and potential inefficiencies in the betting markets. Furthermore, I aim to experiment with innovative modeling techniques and betting strategies, including methods inspired by conformal prediction and robust optimization.


\subsection{Data}\label{data}

The following ten (10) data sources will be considered, loosely organized into groups:

\begin{itemize}
\tightlist
    \item \textbf{Striking/Grappling Metrics} - UFC Stats, ESPN
    \item \textbf{Betting Odds} - Best Fight Odds, FightOdds.io
    \item \textbf{Complete Fighting Histories} - Sherdog, Fight Matrix
    \item \textbf{Judge Scoring} - MMA Decisions
    \item \textbf{Miscellaneous} - Wikipedia, Bet MMA, Tapology
\end{itemize}

As of January 15, 2025, all needed data from these sources have been scraped or obtained from someone else's work (such as an existing GitHub repository). Although most of the data cleaning was already handled by the scraping pipelines implemented, some of the files require additional attention to address edge cases.

In addition to cleaning the data, the following two data-related tasks need to be completed:
\begin{enumerate}
    \item \textit{Cross-Source Matching}. Almost all of the listed data sources have their own unique set of IDs assigned to events, fights, and fighters. All of these must be matched to each other through a set of central ``link'' tables so that unified train and test datasets can be easily created. This will most likely involve a mix of (fuzzy) string matching, metadata matching, and some manual labor.
    \item \textit{Exploratory Data Analysis and Feature Engineering}. Even after cleaning and matching, the data cannot be used directly for modeling since there is a mix of information known before any given fight and information that is known only after a fight has taken place. Features must be created from useful information that informs the outcome of a fight and relies only on data before the corresponding fight takes place. While most of these features will be created based on intuition/domain knowledge with EDA not being the main focus of this project, some degree of analysis and visualization will be needed to sanity check ideas.
\end{enumerate}


\subsection{Methods}\label{methods}

The core idea is to estimate the win probabilities of each fighter in a given fight based only on information that would be available at inference time and to bet on outcomes where those predicted probabilities deviate sufficiently from those implied by the betting odds.

We will accomplish this by framing the problem as a binary classification task and experimenting with logistic regression and tree-based models, as well as the inclusion of calibration layers using Platt scaling, isotonic regression, and Venn-Abers predictors. In particular, Venn-Abers predictors will output a tuple of probabilities that serve as a sort of confidence interval with validity guarantees that reflect the uncertainty in a prediction.

The bet sizes will be computed using an extension of the fractional Kelly criterion to simultaneous outcomes, experimenting with different fractions such as 0.5, 0.25, and 0.1. For pipelines using Venn-Abers calibration, we will also use a robust version of the Kelly criterion that considers the uncertainty in the probability estimates to optimize for the worst-case scenario.

To validate the presence (or lack thereof) of an edge, we will perform backtests over fights within the most recent few years and conduct statistical tests of significance.


\section{Deliverables}\label{deliverables}

\begin{itemize}
\tightlist
    \item Final database(s) with cleaned data and ``link'' tables with IDs matched across sources
    \item Universal train and test datasets to be used by all modeling pipelines
    \item Trained models
    \item Backtesting results for all method/approach combinations mentioned in Methods
    \item Poster and report
\end{itemize}


\section{Timeline}\label{timeline}

\begin{itemize}
\tightlist
    \item Week 1: Proposal, set up meeting schedule with advisors
    \item Weeks 2-5: Finalize meeting schedule with advisors, start writing (draft abstract, introduction, data sections), clean datasets, match IDs across sources, load data to SQLite databases
    \item Weeks 6-8: EDA and feature engineering, continue writing (discuss EDA and feature engineering process), start implementing model training pipelines
    \item Spring Break: Wrap up feature engineering, finish implementing model pipelines
    \item Weeks 9-10: Train all models, implement backtesting framework, continue writing (modeling, backtesting)
    \item Weeks 11-13: Run backtests, wrap up drafts of report and poster, revise based on feedback
    \item Reading Week: Finalize report and submit
\end{itemize}

\end{document}
